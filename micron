#! /usr/bin/env python

'''
Schedule jobs
'''

import sys
import os.path
import argparse
import time
from datetime import datetime
import threading
import subprocess
import logging
import daemon
import random
import yaml, json
import parsedatetime.parsedatetime

TIMEFMT = '%d %b %Y %H:%M:%S'
LOGFMT = '%(asctime)s %(levelname)s %(message)s'
EXITFMT = "Job '%s' exited with %d%s"
RANDFMT = "Randomly waiting for %d s before running job '%s'"

# TODO Measure CPU
# TODO Package
# TODO Timeout
# TODO D-Bus events

def notify(msg):
    '''
    Notify
    '''

    subprocess.call(['urxvt', '-name', 'notsink', '-title', 'micron', '-hold',
                     '-e', 'echo', msg])

def dump(runs, directory):
    '''
    Dump runs information to file
    '''

    with open(directory + '/runs.yaml', 'w') as fhl:
        yaml.safe_dump(runs, fhl, default_flow_style=False)

def run(cfg, parser, name, job):
    '''
    Run job
    '''

    # Sanitise fields
    try:
        maxretry = int(job['maxretry'])
    except (KeyError, ValueError):
        maxretry = 1

    try:
        retry = job['retry']
        assert retry != ''
    except (KeyError, AssertionError):
        retry = '1 hour'

    try:
        rand = job['random']
        assert rand != ''
    except (KeyError, AssertionError):
        rand = None

    # Wait for some random amount of time
    if rand:
        rand = time.mktime(parser.parse(rand)[0])
        rand = datetime.fromtimestamp(rand) - datetime.now()
        rand = random.randrange(int(rand.total_seconds()))
        logging.info(RANDFMT, rand, name)
        time.sleep(rand)

    # Attempt to run job
    for i in range(maxretry):
        logging.info("Running job '%s'", name)

        # Run process
        try:
            cwd = os.path.expanduser(job['cwd'])
            assert cwd != ''
        except (KeyError, AssertionError):
            cwd = None
        proc = subprocess.Popen(job['command'], stdout=subprocess.PIPE,
                                stderr=subprocess.PIPE, shell=True, cwd=cwd)
        out, err = proc.communicate()

        # Print output
        out = out.strip()
        err = err.strip()
        if out:
            logging.info("Job '%s':\n%s", name, out)
        if err:
            logging.warning("Job '%s':\n%s", name, err)

        # Report status
        if proc.returncode == 0:
            logging.info(EXITFMT, name, proc.returncode, '')
            break
        else:
            if i < maxretry - 1:
                msg = "Job '%s' exited with %d. Will retry in %s" % \
                    (name, proc.returncode, retry)
            else:
                msg = "Job '%s' exited with %d. Giving up after %d retries" % \
                    (name, proc.returncode, maxretry)
                try:
                    if json.loads(cfg['notify']):
                        thread = threading.Thread(target=notify, args=(msg,))
                        thread.daemon = True
                        thread.start()
                except KeyError:
                    pass
            logging.warning(msg)

            if i < maxretry - 1:
                retryts = time.mktime(parser.parse(retry)[0])
                retryts = datetime.fromtimestamp(retryts) - datetime.now()
                time.sleep(retryts.total_seconds())

def loop(args, cfg):
    '''
    Event loop
    '''

    # Logging
    if args.foreground:
        logging.basicConfig(level=logging.INFO, format=LOGFMT)
    else:
        logging.basicConfig(level=logging.INFO, format=LOGFMT,
                            filename=args.directory + '/log')

    # Create datetime parser
    parser = parsedatetime.parsedatetime.Calendar()

    # Create thread list
    threads = {}

    try:
        logging.info('Starting main loop')
        while True:
            # Load jobs from file
            try:
                with open(args.directory + '/jobs.yaml') as fhl:
                    jobs = yaml.load(fhl, Loader=yaml.BaseLoader)
            except IOError, exc:
                logging.error(exc)
                return 1

            # Load last runs
            try:
                with open(args.directory + '/runs.yaml') as fhl:
                    runs = yaml.load(fhl, Loader=yaml.BaseLoader)
                assert runs is not None
            except (IOError, AssertionError):
                runs = {}

            # Run jobs when applicable
            now = datetime.now()
            for job in jobs:
                # Is the job running?
                try:
                    if threads[job].isAlive():
                        continue
                    elif 'end' not in runs[job]:
                        runs[job]['end'] = now.strftime(TIMEFMT)
                except KeyError, exc:
                    pass

                # When would the next run be?
                try:
                    nextrun = parser.parse('%s from %s' % (jobs[job]['every'],
                                           runs[job]['end']))[0]
                    nextrun = time.mktime(nextrun)
                except KeyError, exc:
                    nextrun = 0
                    runs[job] = {}

                # Run the job?
                if now > datetime.fromtimestamp(nextrun):
                    try:
                        del runs[job]['end']
                    except KeyError:
                        pass
                    threads[job] = \
                        threading.Thread(target=run,
                                         args=(cfg, parser, job, jobs[job]))
                    threads[job].daemon = True
                    threads[job].start()

            dump(runs, args.directory)
            try:
                time.sleep(int(cfg['loopsleep']))
            except (KeyError, ValueError):
                time.sleep(60)
    except KeyboardInterrupt:
        logging.info('Exited main loop')

def main():
    '''
    Main loop
    '''

    # Arguments
    parser = argparse.ArgumentParser(description="Schedule jobs.")
    parser.add_argument('-d', '--directory', type=os.path.expanduser,
                        default='~/.micron', help="runtime directory")
    parser.add_argument('-f', '--foreground', help="don't daemonise",
                        action='store_true')
    args = parser.parse_args()

    # Create directory
    try:
        os.mkdir(args.directory)
    except OSError:
        pass

    # Load config file
    try:
        with open(args.directory + '/config.yaml') as fhl:
            cfg = yaml.load(fhl, Loader=yaml.BaseLoader)
        assert cfg is not None
    except (IOError, AssertionError):
        cfg = {}

    # Daemonise?
    if not args.foreground:
        umask = os.umask(0)
        os.umask(umask)
        with daemon.DaemonContext(umask=umask):
            loop(args, cfg)
    else:
        loop(args, cfg)

if __name__ == '__main__':
    sys.exit(main())
